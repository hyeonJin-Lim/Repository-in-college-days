{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VVip.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1PUqM6wp77e9i6gYyUEXbUo2N9IFITmOT","authorship_tag":"ABX9TyNwj+QznMeoNzoWrZl15NRw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1X1E2OFdKdiB"},"source":["from google.colab import drive\n","drive.mount('./MyDrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NVZdT3p8aIjR"},"source":["%cd /content/MyDrive/MyDrive/data/train\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBk0mLEmLbvg"},"source":["import keras\n","\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Activation, BatchNormalization, concatenate, AveragePooling2D, GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.layers import add\n","from keras.utils import plot_model\n","from keras.preprocessing.image import load_img\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import os, glob, sys, numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","from glob import glob\n","from tensorflow.keras.models import Sequential\n","\n","from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","#from keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n","from tensorflow.keras.models import Sequential\n","import os, re, glob\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dropout, Activation, Dense\n","from keras.layers import Flatten, Convolution2D, MaxPooling2D\n","from keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ubb_9u9Ilgo"},"source":["groups_folder_path = \"/content/MyDrive/MyDrive/data/train/\"\n","categories = [\"Fe\", \"Mg\"]\n"," \n","num_classes = len(categories)\n","  \n","image_w = 64\n","image_h = 64\n","  \n","X = []\n","Y = []\n","  \n","for idex, categorie in enumerate(categories):\n","    label = [0 for i in range(num_classes)]\n","    label[idex] = 1\n","    image_dir = groups_folder_path + categorie + '/'\n","  \n","    for top, dir, f in os.walk(image_dir):\n","        for filename in f:\n","            print(image_dir+filename)\n","            img = cv2.imread(image_dir+filename)\n","            img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n","            X.append(img/256)\n","            Y.append(label)\n"," \n","X = np.array(X)\n","Y = np.array(Y)\n"," \n","X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n","xy = (X_train, X_test, Y_train, Y_test)\n"," \n","np.save(\"/content/MyDrive/MyDrive/data/train/numpy/data.npy\", xy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMg_OMbOJMh8"},"source":["X_train, X_test, Y_train, Y_test = np.load('/content/MyDrive/MyDrive/data/train/numpy/data.npy', allow_pickle=True)\n"," \n","model = Sequential()\n","model = Sequential()\n","model.add(Convolution2D(16, 3, 3, activation='relu',input_shape=X_train.shape[1:]))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Convolution2D(64, 3, 3,  activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n"," \n","#model.add(Convolution2D(64, 3, 3))\n","#model.add(MaxPooling2D(pool_size=(2, 2)))\n","#model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes,activation = 'softmax'))\n","plot_model(model, show_shapes=True, to_file='residual_module.png')\n","model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","#model.fit(X_train, Y_train, batch_size=32, epochs=100)\n"," \n","#model.save('FE')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SA1YVh8zkTmj"},"source":["print(np.asarray(X_train).shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kf-KQxkRSLZ4"},"source":["import os, glob, numpy as np\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","\n","X_train, X_test, Y_train, Y_test = np.load('/MyDrive/MyDrive/data/train/numpy/Fe.npy', allow_pickle=True)\n","print(np.asarray(X).shape)\n","print(np.bincount(Y_train))\n","print(np.bincount(Y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLNynHCMcpS9"},"source":["X_train = np.array(X_train, dtype=np.float32) / 255\n","\n","X_test = np.array(X_test, dtype=np.float32) / 255"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbxED07J4QJw"},"source":["growth_rate = 32\n","theta = 0.5\n","\n","def DenseBlock(x, num):\n","    layer_list = [x]\n","    for i in range(num): # layer 수가 늘어날수록 layer_list에 있는 x에 대해 새로운 x가 concatenate 된다\n","        x1 = BatchNormalization()(x)\n","        x1 = Activation('relu')(x1)\n","        x1 = Convolution2D(growth_rate*4, kernel_size=1, padding='same', use_bias=False)(x1)\n","        x1 = BatchNormalization()(x1)\n","        x1 = Activation('relu')(x1)\n","        x1 = Convolution2D(growth_rate, kernel_size=3, padding='same', use_bias=False)(x1)\n","        layer_list.append(x1)\n","        x = concatenate(layer_list, axis=-1) # channel에 대해 layer들을 concatenate\n","    return x\n","\n","\n","def Transition_layer(x, name):\n","    num_ch = int(x.get_shape().as_list()[-1] * theta) # theta 비율만큼 channel 수를 줄임\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(num_ch, kernel_size=3, padding='same', use_bias=False)(x)\n","    x = AveragePooling2D(pool_size=2, strides=2, padding='same', name=name)(x)\n","    \n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCRmq_aE0ePB"},"source":["inputs = Input(shape=(64, 64, 3))\n","x = Convolution2D(64, kernel_size=7, strides=2, padding='same', use_bias=False)(inputs) # (None,112, 112, 64)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","\n","x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # (None,56, 56, 64)\n","\n","x = DenseBlock(x, 6) # (None,56, 56, 256)\n","x = Transition_layer(x, 'transition_layer_1') # (None,28, 28, 128)\n","x = DenseBlock(x, 12) # (None,28, 28, 512)\n","x = Transition_layer(x, 'transition_layer_2') # (None,14, 14, 256)\n","x = DenseBlock(x, 24) # (None,14, 14, 1024)\n","x = Transition_layer(x, 'transition_layer_3') # (None,7, 7, 512)\n","x = DenseBlock(x, 16) # (None,7, 7, 1024)\n","x = GlobalAveragePooling2D()(x) # (None,1024)\n","outputs = Dense(2, activation='softmax')(x) # (None, 10)\n","\n","model = Model(inputs=inputs, outputs=outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"irgpqBFI8-QH"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TmRPqTHQvQq"},"source":["plot_model(model, show_shapes=True, to_file='residual_module.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qA-mQ4Wl9YiO"},"source":["model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmYwV5jKDxY1"},"source":["X = np.array(X)\n","Y = np.array(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_GTDfRkHcwa"},"source":["print(np.asarray(X_train).shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tgT_6iKRQrja"},"source":["model.fit(X_train, Y_train, batch_size=32, epochs=100)"],"execution_count":null,"outputs":[]}]}